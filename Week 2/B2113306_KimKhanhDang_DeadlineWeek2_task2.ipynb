{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyP8P6eD92ozBiTNy0akm8S7"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "unSgMsWTgC76",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1723469634997,
     "user_tz": -420,
     "elapsed": 18975,
     "user": {
      "displayName": "Kim Khanh Dang B2113306",
      "userId": "10170023914068149393"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-08-22T13:01:40.068469Z",
     "start_time": "2024-08-22T13:01:40.048918800Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tensorflow._api.v2.keras import Sequential\n",
    "from tensorflow._api.v2.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# iris = datasets.load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "iris = fetch_openml(name='iris', version=1, parser='auto', as_frame=True)\n",
    "Data = iris.data\n",
    "target = iris.target"
   ],
   "metadata": {
    "collapsed": true,
    "id": "NqLViRl6gwQ5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1723469694450,
     "user_tz": -420,
     "elapsed": 327,
     "user": {
      "displayName": "Kim Khanh Dang B2113306",
      "userId": "10170023914068149393"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-08-22T13:01:42.512368900Z",
     "start_time": "2024-08-22T13:01:42.448136100Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(Data)\n",
    "print(target)\n",
    "target = target.replace({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n",
    "target = pd.to_numeric(target, errors='coerce').astype(int)\n",
    "print(target)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLRA07o9hCkd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1723469696522,
     "user_tz": -420,
     "elapsed": 332,
     "user": {
      "displayName": "Kim Khanh Dang B2113306",
      "userId": "10170023914068149393"
     }
    },
    "outputId": "2b61f6dc-3208-4de2-a3fa-8dbd091e8b34",
    "ExecuteTime": {
     "end_time": "2024-08-22T13:01:44.069404300Z",
     "start_time": "2024-08-22T13:01:44.035698Z"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepallength  sepalwidth  petallength  petalwidth\n",
      "0            5.1         3.5          1.4         0.2\n",
      "1            4.9         3.0          1.4         0.2\n",
      "2            4.7         3.2          1.3         0.2\n",
      "3            4.6         3.1          1.5         0.2\n",
      "4            5.0         3.6          1.4         0.2\n",
      "..           ...         ...          ...         ...\n",
      "145          6.7         3.0          5.2         2.3\n",
      "146          6.3         2.5          5.0         1.9\n",
      "147          6.5         3.0          5.2         2.0\n",
      "148          6.2         3.4          5.4         2.3\n",
      "149          5.9         3.0          5.1         1.8\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "0         Iris-setosa\n",
      "1         Iris-setosa\n",
      "2         Iris-setosa\n",
      "3         Iris-setosa\n",
      "4         Iris-setosa\n",
      "            ...      \n",
      "145    Iris-virginica\n",
      "146    Iris-virginica\n",
      "147    Iris-virginica\n",
      "148    Iris-virginica\n",
      "149    Iris-virginica\n",
      "Name: class, Length: 150, dtype: category\n",
      "Categories (3, object): ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: class, Length: 150, dtype: int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8024\\2074519923.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  target = target.replace({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8024\\2074519923.py:3: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  target = target.replace({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Data, target, test_size=0.2, shuffle=True, random_state=42)"
   ],
   "metadata": {
    "id": "Mh27Eukih1QO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1723469701388,
     "user_tz": -420,
     "elapsed": 343,
     "user": {
      "displayName": "Kim Khanh Dang B2113306",
      "userId": "10170023914068149393"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-08-22T13:01:45.534735900Z",
     "start_time": "2024-08-22T13:01:45.504271400Z"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "model = Sequential()\n",
    "model.add(Dense(3, use_bias=True, input_shape=(4,), activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xhRVGJeOjUA7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1723469955972,
     "user_tz": -420,
     "elapsed": 8287,
     "user": {
      "displayName": "Kim Khanh Dang B2113306",
      "userId": "10170023914068149393"
     }
    },
    "outputId": "b176a381-a0f2-49ae-ed30-f28f0292328d",
    "ExecuteTime": {
     "end_time": "2024-08-22T13:01:51.372769800Z",
     "start_time": "2024-08-22T13:01:46.951828800Z"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.distribute.input_lib' has no attribute 'DistributedDatasetInterface'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39madd(Dense(\u001B[38;5;241m3\u001B[39m, use_bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, input_shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m4\u001B[39m,), activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msoftmax\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m      5\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m----> 6\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m150\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1137\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1131\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cluster_coordinator \u001B[38;5;241m=\u001B[39m cluster_coordinator\u001B[38;5;241m.\u001B[39mClusterCoordinator(\n\u001B[0;32m   1132\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy)\n\u001B[0;32m   1134\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy\u001B[38;5;241m.\u001B[39mscope(), \\\n\u001B[0;32m   1135\u001B[0m      training_utils\u001B[38;5;241m.\u001B[39mRespectCompiledTrainableState(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1136\u001B[0m   \u001B[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001B[39;00m\n\u001B[1;32m-> 1137\u001B[0m   data_handler \u001B[38;5;241m=\u001B[39m \u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_handler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1138\u001B[0m \u001B[43m      \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1139\u001B[0m \u001B[43m      \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1140\u001B[0m \u001B[43m      \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1141\u001B[0m \u001B[43m      \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1142\u001B[0m \u001B[43m      \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1143\u001B[0m \u001B[43m      \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1144\u001B[0m \u001B[43m      \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1145\u001B[0m \u001B[43m      \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1146\u001B[0m \u001B[43m      \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1147\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1148\u001B[0m \u001B[43m      \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1149\u001B[0m \u001B[43m      \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1150\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1151\u001B[0m \u001B[43m      \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1153\u001B[0m   \u001B[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001B[39;00m\n\u001B[0;32m   1154\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[1;32m~\\PycharmProjects\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1397\u001B[0m, in \u001B[0;36mget_data_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1395\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cluster_coordinator\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1396\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1397\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1151\u001B[0m, in \u001B[0;36mDataHandler.__init__\u001B[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001B[0m\n\u001B[0;32m   1148\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution \u001B[38;5;241m=\u001B[39m steps_per_execution\n\u001B[0;32m   1149\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution_value \u001B[38;5;241m=\u001B[39m steps_per_execution\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m-> 1151\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m \u001B[43mselect_data_adapter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1152\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapter \u001B[38;5;241m=\u001B[39m adapter_cls(\n\u001B[0;32m   1153\u001B[0m     x,\n\u001B[0;32m   1154\u001B[0m     y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1163\u001B[0m     distribution_strategy\u001B[38;5;241m=\u001B[39mdistribute_lib\u001B[38;5;241m.\u001B[39mget_strategy(),\n\u001B[0;32m   1164\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel)\n\u001B[0;32m   1166\u001B[0m strategy \u001B[38;5;241m=\u001B[39m distribute_lib\u001B[38;5;241m.\u001B[39mget_strategy()\n",
      "File \u001B[1;32m~\\PycharmProjects\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:987\u001B[0m, in \u001B[0;36mselect_data_adapter\u001B[1;34m(x, y)\u001B[0m\n\u001B[0;32m    985\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect_data_adapter\u001B[39m(x, y):\n\u001B[0;32m    986\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 987\u001B[0m   adapter_cls \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mcls\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01min\u001B[39;00m ALL_ADAPTER_CLS \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mcan_handle(x, y)]\n\u001B[0;32m    988\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m adapter_cls:\n\u001B[0;32m    989\u001B[0m     \u001B[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001B[39;00m\n\u001B[0;32m    990\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    991\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to find data adapter that can handle \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    992\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    993\u001B[0m             _type_name(x), _type_name(y)))\n",
      "File \u001B[1;32m~\\PycharmProjects\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:987\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    985\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect_data_adapter\u001B[39m(x, y):\n\u001B[0;32m    986\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 987\u001B[0m   adapter_cls \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mcls\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01min\u001B[39;00m ALL_ADAPTER_CLS \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcan_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m]\n\u001B[0;32m    988\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m adapter_cls:\n\u001B[0;32m    989\u001B[0m     \u001B[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001B[39;00m\n\u001B[0;32m    990\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    991\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to find data adapter that can handle \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    992\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    993\u001B[0m             _type_name(x), _type_name(y)))\n",
      "File \u001B[1;32m~\\PycharmProjects\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:706\u001B[0m, in \u001B[0;36mDatasetAdapter.can_handle\u001B[1;34m(x, y)\u001B[0m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcan_handle\u001B[39m(x, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    705\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(x, (data_types\u001B[38;5;241m.\u001B[39mDatasetV1, data_types\u001B[38;5;241m.\u001B[39mDatasetV2)) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m--> 706\u001B[0m           \u001B[43m_is_distributed_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\DeepLearning\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1696\u001B[0m, in \u001B[0;36m_is_distributed_dataset\u001B[1;34m(ds)\u001B[0m\n\u001B[0;32m   1695\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_is_distributed_dataset\u001B[39m(ds):\n\u001B[1;32m-> 1696\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ds, \u001B[43minput_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDistributedDatasetInterface\u001B[49m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'tensorflow.python.distribute.input_lib' has no attribute 'DistributedDatasetInterface'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFYFGXvlmDZq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1723469960852,
     "user_tz": -420,
     "elapsed": 481,
     "user": {
      "displayName": "Kim Khanh Dang B2113306",
      "userId": "10170023914068149393"
     }
    },
    "outputId": "ae0cef41-f697-4946-a3a1-5447119d5031",
    "ExecuteTime": {
     "end_time": "2024-08-22T13:01:51.378764300Z",
     "start_time": "2024-08-22T13:01:51.373769300Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
